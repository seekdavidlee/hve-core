---
description: 'Deep expertise for Method 2: Design Research, covering advanced interview techniques, ethnographic observation, and evidence triangulation'
applyTo: '**/.copilot-tracking/dt/**/method-02*'
---

# DT Method 02 Deep: Advanced Design Research Techniques

On-demand deep reference for Method 2. The coach loads this file when users encounter complex research scenarios requiring advanced interview techniques, ethnographic methods, evidence triangulation, or manufacturing-specific research patterns that exceed the method-tier guidance. The method-tier's Research Designer and Empathy Guide coaching hats provide foundational interview coaching and research planning; this file extends those hats with specialized protocols for complex research environments.

## Advanced Interview Techniques

The method-tier file covers open-ended questioning, progressive deepening, workaround investigation, and recovery strategies for common interview dynamics. The techniques below address structured protocols for scenarios where standard approaches produce insufficient depth or encounter resistance.

### Laddering Protocol

Move from surface observations to underlying motivations through progressive why-chain questioning:

* Surface level: capture what the user does and how they describe it.
* Stated reason level: ask why they do it that way to surface their conscious rationale.
* Underlying value level: ask why that rationale matters to reveal priorities and tradeoffs.
* Core need level: ask what would change if that value were fully met to expose the fundamental requirement.

Stop the ladder when the user begins repeating answers, reaches emotional territory, or arrives at organizational philosophy. Pushing past these signals damages rapport.

Coaching prompt: "You've described what happens. What would you say drives that particular approach over alternatives?"

### Critical Incident Technique

Anchor interviews around specific memorable events rather than general opinions. Concrete incidents bypass generalization bias and surface environmental details that abstract questions miss.

* Ask the user to recall a recent specific instance of the problem, not a typical one.
* Reconstruct the full sequence: what happened before, during, and after the incident.
* Capture sensory details (what they saw, heard, felt) to surface environmental factors invisible in general descriptions.
* Distinguish between the user's interpretation of the event and the observable facts they report.

Coaching prompt: "Can you walk me through the last time this went wrong, starting from the moment you first noticed something was off?"

### Projective Techniques

Indirect questioning surfaces attitudes users cannot or will not articulate directly. Use these when direct questions produce guarded or socially desirable responses.

* Role reversal: "What would you tell someone starting in your role about how this really works?"
* Ideal scenario: "If you could redesign this process from scratch with no constraints, what would change first?"
* Third-party attribution: "Some teams have described this as frustrating. What has your experience been?"

Coaching prompt: "If a new team member asked you for the unofficial guide to making this work, what would you include?"

### Context-Triggered Interviews

Conduct interviews while users perform actual tasks rather than in meeting rooms. The environment triggers questions that neither the researcher nor the user would generate from memory alone.

* Position the interview at the workstation, production line, or workspace where the task occurs.
* Let the task sequence drive the questions rather than a prepared script.
* Ask about each step as the user performs it: "What are you checking for here?" and "What happens if this step fails?"
* Note environmental factors (noise, interruptions, tool placement) that the user treats as normal but affect task performance.

Coaching prompt: "Show me how you actually do this. I'll ask questions as we go rather than working from a list."

### Group Dynamics Management

Group interviews surface insights different from individual sessions: shared memories, corrective accounts, and consensus patterns. They also introduce dynamics that require active management.

* Rotate direct questions to quieter participants rather than relying on open-floor responses.
* When a dominant voice asserts a conclusion, ask others: "Is that how it works on your shift too?"
* Use disagreements productively; conflicting accounts between group members reveal process variation worth documenting.
* Reserve group sessions for exploring shared processes. Use individual sessions for personal workflows and sensitive topics.

Coaching prompt: "We've heard one perspective on how this works. Does everyone experience it the same way, or does it vary?"

## Ethnographic Observation Methods

The method-tier file defines observation focus areas (physical conditions, technology interaction, workflow sequences, communication patterns, workaround artifacts). The protocols below provide systematic approaches for extended or complex observation scenarios.

### Contextual Inquiry Protocol

Combine observation with in-the-moment questioning using a master-apprentice model. Position the user as the expert teaching their work to the researcher.

* Ask the user to narrate their task as they perform it: "Talk me through what you're doing and why."
* Interrupt only to clarify observed actions: "I noticed you checked that screen before proceeding. What were you looking for?"
* Distinguish between what the user does and what they say they do. Note discrepancies without challenging in the moment.
* Record the physical environment, tool layout, and information sources the user accesses during the task.

Coaching prompt: "Treat me as someone learning your job for the first time. Walk me through this task the way you actually do it."

### Day-in-the-Life Mapping

Track a complete work cycle across hours or an entire shift to identify rhythm-dependent needs invisible in snapshot observations.

* Map task sequences, transitions between activities, interruptions, and energy patterns over the full period.
* Note which tasks cluster together, which require context-switching, and where delays accumulate.
* Capture transition moments between tasks: these handoff points often contain information loss and coordination friction.
* Identify patterns that vary by time of day, workload level, or staffing availability.

Coaching prompt: "Walk me through your day from when you arrive. Where do the biggest transitions happen between different types of work?"

### Artifact Analysis

User-created artifacts (sticky notes, modified tools, reference cards, spreadsheet workarounds) reveal needs without researcher influence. Each artifact represents a gap between the designed system and actual requirements.

* Document what the artifact is, who created it, and what need it serves.
* Ask how the artifact came to exist: "When did you start doing this, and what problem were you solving?"
* Look for artifacts that multiple users create independently, indicating a systematic gap rather than individual preference.
* Photograph or sketch artifact placement in the workspace to capture spatial relationships with other tools.

Coaching prompt: "I notice you have [artifact] here. How did that come about, and what would happen if it disappeared?"

### Shadow Observation

Passive observation for extended periods without researcher interaction minimizes observer effect and captures behaviors users self-edit during active interviews.

* Establish presence before beginning formal observation. Spend initial time as a visible but non-interacting observer until the user resumes natural behavior.
* Record behaviors, task sequences, and environmental interactions without interrupting flow.
* Note moments where the user hesitates, backtracks, or checks with others; these signal uncertainty or process gaps.
* Save questions for a debrief session after the observation period rather than interrupting during the task.

Coaching prompt: "I'd like to observe your work for a while without interrupting. Afterward, I'll have some questions about what I noticed."

## Evidence Triangulation

The method-tier file establishes evidence standards: anchor insights to direct quotes, look for patterns across users, and actively seek contradicting evidence. The frameworks below provide structured approaches for cross-source validation and research quality assessment.

### Multi-Source Validation

Cross-reference three evidence types to strengthen findings: what users say (interview data), what users do (observation data), and what artifacts show (physical evidence).

* An insight supported by all three sources carries stronger weight than one supported by a single source.
* Document convergence (sources agree), divergence (sources disagree), and gaps (a source type is missing for this insight).
* When only one source supports a finding, flag it as preliminary and design additional research to validate or challenge it.
* Track which evidence types are overrepresented in the findings. Interview-heavy research benefits from additional observation.

Coaching prompt: "For this finding, what did users say about it, what did you observe directly, and what artifacts support or contradict it?"

### Contradiction Analysis

When sources disagree, the contradiction itself is a finding worth documenting. Contradictions reveal system pressures, aspirational thinking, or context-dependent variation.

* Say-do gaps: users often describe ideal behavior in interviews but follow different patterns in practice. Both accounts contain truth about different aspects of the experience.
* Role-based contradictions: operators and engineers may describe the same process differently because each interacts with different facets of it.
* Temporal contradictions: a process may work differently under normal conditions versus peak load or understaffing.
* Investigate contradictions rather than resolving them prematurely. Document both accounts and the conditions under which each holds true.

Coaching prompt: "These two accounts conflict. Rather than deciding which is correct, what conditions might make both true?"

### Saturation Detection

Recognize when additional research produces diminishing returns to allocate remaining effort effectively.

* Track new insight emergence across sessions. Saturation approaches when sessions confirm existing patterns without surfacing new themes.
* Distinguish true saturation from premature closure: limited user diversity or single-context observation can create a false sense of completeness.
* Test saturation by interviewing a user from an underrepresented group or observing during a different time period. If new themes emerge, saturation has not been reached.
* Partial saturation is common: some theme areas may be saturated while others remain underexplored.

Coaching prompt: "Are the last few sessions confirming what you already know, or are new themes still emerging?"

### Bias Audit Checklist

Systematic self-review at each research phase surfaces researcher biases before they shape findings.

* Confirmation bias: review whether interview follow-up questions consistently pursue evidence supporting existing hypotheses while overlooking contradicting signals.
* Selection bias: check whether research targets represent the full user population or favor accessible, agreeable, or articulate participants.
* Interpretation bias: examine whether ambiguous findings are being framed to fit preferred narratives rather than documented as genuinely ambiguous.
* Recency bias: assess whether recent interviews carry disproportionate weight relative to earlier sessions with equally valid data.

Coaching prompt: "Looking at your research targets so far, whose perspective is missing or underrepresented?"

## Manufacturing Research Patterns

The method-tier file includes cross-domain constraint patterns for manufacturing (noise, contamination, safety protocols). The protocols below address manufacturing-specific research designs that account for shift variation, safety restrictions, and the distinct perspectives of operators versus engineers.

### Shift Observation Protocols

Manufacturing processes vary across shifts in ways that affect research validity. Design research to capture these differences rather than assuming day-shift observations represent the full picture.

* Day shifts typically have more management oversight, support resources, and established routines.
* Night and weekend shifts operate with reduced staffing and often develop workarounds invisible to day-shift management.
* Handoff periods between shifts reveal information transfer gaps, process interpretation differences, and coordination challenges.
* Schedule observations across at least two different shifts before drawing conclusions about a process.

Coaching prompt: "Your observations so far cover one shift. How might this process look different with different staffing levels or supervision?"

### Safety-Constrained Research

Safety-sensitive environments impose constraints on observation and interview methods that require advance planning.

* Identify PPE requirements, restricted zones, and observation clearance procedures before scheduling research sessions.
* Plan observation windows during natural pauses: shift changes, maintenance windows, and scheduled breaks minimize disruption to active operations.
* Conduct detailed interviews outside the restricted area immediately after observation sessions while environmental context remains fresh.
* Some processes cannot be observed during active operation. Combine off-line walkthroughs with operator narration as an alternative.

Coaching prompt: "Before entering the research environment, what safety protocols and access requirements need to be in place?"

### Operator vs Engineer Perspectives

Operators and engineers hold systematically different mental models of the same equipment and processes. Both perspectives are valid, and contradictions between them reveal design-implementation gaps.

* Operators focus on daily use, sensory cues (sounds, vibrations, visual indicators), and practical workarounds developed through experience.
* Engineers focus on system design, specifications, failure modes, and intended operating procedures.
* Interview both groups about the same process and document where their accounts diverge. Divergence points indicate where designed workflows differ from actual practice.
* Avoid privileging one perspective over the other. Operator knowledge captures real conditions; engineer knowledge captures design intent.

Coaching prompt: "You've heard the operator's description of this process. How does the engineering team describe the same sequence?"

### Machine-Human Interface Observation

Watch operators interact with equipment interfaces under real operating conditions to surface usability issues invisible in documentation or engineering reviews.

* Observe physical constraints: gloves, contamination, protective equipment, lighting, and noise levels that affect how operators interact with controls and displays.
* Document the gap between designed interaction (clean hands, quiet environment, full attention) and actual interaction (gloved hands, noisy floor, split attention).
* Note information the operator seeks from the interface versus information the interface presents. Mismatches indicate display design gaps.
* Capture workarounds operators use to compensate for interface limitations: tape marks on screens, memorized sequences replacing menu navigation, verbal relay of readings.

Coaching prompt: "Watch how the operator actually uses this interface. Where does the physical environment make the designed interaction difficult?"

* All DT coaching artifacts are scoped to `.copilot-tracking/dt/{project-slug}/`. Never write DT artifacts directly under `.copilot-tracking/dt/` without a project-slug directory.
